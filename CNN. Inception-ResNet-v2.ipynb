{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inception-ResNet-v1과 모든 모듈의 구조가 같지만, 1x1 Conv 레이어를 통과하고 나온 값의 채널 수가 다르다. 예를 들어, InceptionResA의 경우 v1은 256, v2는 384이다. \n",
    "\n",
    "\n",
    "- Fig.15에 나온 채널 수는 v1 기준이기 때문에 v2 구현 시에는 하나하나 계산해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Stem(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stem, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvBlock(3, 32, kernel_size=3, stride=2, padding=0),\n",
    "            ConvBlock(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            ConvBlock(32, 64, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.maxpool_96 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.maxpool_192 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.conv_96 = ConvBlock(64, 96, kernel_size=3, stride=2, padding=0)\n",
    "        self.conv_192 = ConvBlock(192, 192, kernel_size=3, stride=2, padding=0) # 논문엔 stride = 2 표시가 안된듯\n",
    "        \n",
    "        self.branch2_1 = nn.Sequential(\n",
    "            ConvBlock(160, 64, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(64, 96, kernel_size=3, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2_2 = nn.Sequential(\n",
    "            ConvBlock(160, 64, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            ConvBlock(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(64, 96, kernel_size=3, stride=1, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.branch1(x)\n",
    "        \n",
    "        x1_1 = self.maxpool_96(x)\n",
    "        x1_2 = self.conv_96(x)\n",
    "        \n",
    "        x = torch.cat([x1_1, x1_2], dim=1)\n",
    "        \n",
    "        x2_1 = self.branch2_1(x)\n",
    "        x2_2 = self.branch2_2(x)\n",
    "        \n",
    "        x = torch.cat([x2_1, x2_2], dim=1)\n",
    "        \n",
    "        x3_1 = self.conv_192(x)\n",
    "        x3_2 = self.maxpool_192(x)\n",
    "        \n",
    "        return torch.cat([x3_1, x3_2], dim=1) # 아웃풋 채널: 384 = InceptionResA 인풋 채널\n",
    "    \n",
    "\n",
    "class InceptionResA(nn.Module):\n",
    "    def __init__(self, in_ch, scale):\n",
    "        super(InceptionResA, self).__init__()\n",
    "        \n",
    "        self.scaling = scale\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 32, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 32, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(32, 32, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 32, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(32, 48, kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(48, 64, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        # 이 conv1x1 필터의 아웃풋 채널이 인풋으로 들어온 feature map의 채널과 같아야 더해질 수 있음\n",
    "        self.conv1x1 = nn.Conv2d(128, 384, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pre_x = x\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        \n",
    "        x = torch.cat([x1, x2, x3], dim=1)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        out = pre_x + x*self.scaling\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out # 아웃풋 채널: 384 = ReductionA 인풋 채널\n",
    "    \n",
    "    \n",
    "class ReductionA(nn.Module): # k=256, l=256, m=384, n=384\n",
    "    def __init__(self, in_ch, k, l, m, n):\n",
    "        super(ReductionA, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, n, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, k, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(k, l, kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(l, m, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        \n",
    "        return torch.cat([x1, x2, x3], dim=1) # 아웃풋 채널: 1152 = InceptionResB 인풋 채널\n",
    "    \n",
    "    \n",
    "class InceptionResB(nn.Module):\n",
    "    def __init__(self, in_ch, scale):\n",
    "        super(InceptionResB, self).__init__()\n",
    "        \n",
    "        self.scaling = scale\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 192, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 128, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(160, 192, kernel_size=(7,1), stride=1, padding=(3,0)))\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(384, 1152, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pre_x = x\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        out = pre_x + x*self.scaling\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out # 아웃풋 채널: 1152 = ReductionB 인풋 채널\n",
    "    \n",
    "    \n",
    "class ReductionB(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(ReductionB, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 256, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(256, 384, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 256, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(256, 288, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 256, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(256, 288, kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(288, 320, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x4 = self.branch4(x) \n",
    "        \n",
    "        return torch.cat([x1, x2, x3, x4], dim=1) # 아웃풋 채널: 2144 = InceptionResC 인풋 채널\n",
    "    \n",
    "\n",
    "class InceptionResC(nn.Module):\n",
    "    def __init__(self, in_ch, scale):\n",
    "        super(InceptionResC, self).__init__()\n",
    "        \n",
    "        self.scaling = scale\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 192, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 192, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n",
    "            ConvBlock(224, 256, kernel_size=(3,1), stride=1, padding=(1,0)))\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(448, 2144, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pre_x = x\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        out = pre_x + x*self.scaling\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_ResNet_V2(nn.Module):\n",
    "    def __init__(self, num_classes = 1000):\n",
    "        super(Inception_ResNet_V2, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(Stem())\n",
    "        \n",
    "        for _ in range(5):\n",
    "            layers.append(InceptionResA(384, 0.17))\n",
    "            \n",
    "        layers.append(ReductionA(384, 256, 256, 384, 384))\n",
    "        \n",
    "        for _ in range(10):\n",
    "            layers.append(InceptionResB(1152, 0.1))\n",
    "            \n",
    "        layers.append(ReductionB(1152))\n",
    "        \n",
    "        for _ in range(5):\n",
    "            layers.append(InceptionResC(2144, 0.2))\n",
    "        \n",
    "        self.feature = nn.Sequential(*layers)        \n",
    "        \n",
    "        self.globalavgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        self.linear = nn.Linear(2144, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.feature(x)\n",
    "        x = self.globalavgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 149, 149]             864\n",
      "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
      "              ReLU-3         [-1, 32, 149, 149]               0\n",
      "         ConvBlock-4         [-1, 32, 149, 149]               0\n",
      "            Conv2d-5         [-1, 32, 147, 147]           9,216\n",
      "       BatchNorm2d-6         [-1, 32, 147, 147]              64\n",
      "              ReLU-7         [-1, 32, 147, 147]               0\n",
      "         ConvBlock-8         [-1, 32, 147, 147]               0\n",
      "            Conv2d-9         [-1, 64, 147, 147]          18,432\n",
      "      BatchNorm2d-10         [-1, 64, 147, 147]             128\n",
      "             ReLU-11         [-1, 64, 147, 147]               0\n",
      "        ConvBlock-12         [-1, 64, 147, 147]               0\n",
      "        MaxPool2d-13           [-1, 64, 73, 73]               0\n",
      "           Conv2d-14           [-1, 96, 73, 73]          55,296\n",
      "      BatchNorm2d-15           [-1, 96, 73, 73]             192\n",
      "             ReLU-16           [-1, 96, 73, 73]               0\n",
      "        ConvBlock-17           [-1, 96, 73, 73]               0\n",
      "           Conv2d-18           [-1, 64, 73, 73]          10,240\n",
      "      BatchNorm2d-19           [-1, 64, 73, 73]             128\n",
      "             ReLU-20           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-21           [-1, 64, 73, 73]               0\n",
      "           Conv2d-22           [-1, 96, 71, 71]          55,296\n",
      "      BatchNorm2d-23           [-1, 96, 71, 71]             192\n",
      "             ReLU-24           [-1, 96, 71, 71]               0\n",
      "        ConvBlock-25           [-1, 96, 71, 71]               0\n",
      "           Conv2d-26           [-1, 64, 73, 73]          10,240\n",
      "      BatchNorm2d-27           [-1, 64, 73, 73]             128\n",
      "             ReLU-28           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-29           [-1, 64, 73, 73]               0\n",
      "           Conv2d-30           [-1, 64, 73, 73]          28,672\n",
      "      BatchNorm2d-31           [-1, 64, 73, 73]             128\n",
      "             ReLU-32           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-33           [-1, 64, 73, 73]               0\n",
      "           Conv2d-34           [-1, 64, 73, 73]          28,672\n",
      "      BatchNorm2d-35           [-1, 64, 73, 73]             128\n",
      "             ReLU-36           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-37           [-1, 64, 73, 73]               0\n",
      "           Conv2d-38           [-1, 96, 71, 71]          55,296\n",
      "      BatchNorm2d-39           [-1, 96, 71, 71]             192\n",
      "             ReLU-40           [-1, 96, 71, 71]               0\n",
      "        ConvBlock-41           [-1, 96, 71, 71]               0\n",
      "           Conv2d-42          [-1, 192, 35, 35]         331,776\n",
      "      BatchNorm2d-43          [-1, 192, 35, 35]             384\n",
      "             ReLU-44          [-1, 192, 35, 35]               0\n",
      "        ConvBlock-45          [-1, 192, 35, 35]               0\n",
      "        MaxPool2d-46          [-1, 192, 35, 35]               0\n",
      "             Stem-47          [-1, 384, 35, 35]               0\n",
      "           Conv2d-48           [-1, 32, 35, 35]          12,288\n",
      "      BatchNorm2d-49           [-1, 32, 35, 35]              64\n",
      "             ReLU-50           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-51           [-1, 32, 35, 35]               0\n",
      "           Conv2d-52           [-1, 32, 35, 35]          12,288\n",
      "      BatchNorm2d-53           [-1, 32, 35, 35]              64\n",
      "             ReLU-54           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-55           [-1, 32, 35, 35]               0\n",
      "           Conv2d-56           [-1, 32, 35, 35]           9,216\n",
      "      BatchNorm2d-57           [-1, 32, 35, 35]              64\n",
      "             ReLU-58           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-59           [-1, 32, 35, 35]               0\n",
      "           Conv2d-60           [-1, 32, 35, 35]          12,288\n",
      "      BatchNorm2d-61           [-1, 32, 35, 35]              64\n",
      "             ReLU-62           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-63           [-1, 32, 35, 35]               0\n",
      "           Conv2d-64           [-1, 48, 35, 35]          13,824\n",
      "      BatchNorm2d-65           [-1, 48, 35, 35]              96\n",
      "             ReLU-66           [-1, 48, 35, 35]               0\n",
      "        ConvBlock-67           [-1, 48, 35, 35]               0\n",
      "           Conv2d-68           [-1, 64, 35, 35]          27,648\n",
      "      BatchNorm2d-69           [-1, 64, 35, 35]             128\n",
      "             ReLU-70           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-71           [-1, 64, 35, 35]               0\n",
      "           Conv2d-72          [-1, 384, 35, 35]          49,536\n",
      "             ReLU-73          [-1, 384, 35, 35]               0\n",
      "             ReLU-74          [-1, 384, 35, 35]               0\n",
      "    InceptionResA-75          [-1, 384, 35, 35]               0\n",
      "           Conv2d-76           [-1, 32, 35, 35]          12,288\n",
      "      BatchNorm2d-77           [-1, 32, 35, 35]              64\n",
      "             ReLU-78           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-79           [-1, 32, 35, 35]               0\n",
      "           Conv2d-80           [-1, 32, 35, 35]          12,288\n",
      "      BatchNorm2d-81           [-1, 32, 35, 35]              64\n",
      "             ReLU-82           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-83           [-1, 32, 35, 35]               0\n",
      "           Conv2d-84           [-1, 32, 35, 35]           9,216\n",
      "      BatchNorm2d-85           [-1, 32, 35, 35]              64\n",
      "             ReLU-86           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-87           [-1, 32, 35, 35]               0\n",
      "           Conv2d-88           [-1, 32, 35, 35]          12,288\n",
      "      BatchNorm2d-89           [-1, 32, 35, 35]              64\n",
      "             ReLU-90           [-1, 32, 35, 35]               0\n",
      "        ConvBlock-91           [-1, 32, 35, 35]               0\n",
      "           Conv2d-92           [-1, 48, 35, 35]          13,824\n",
      "      BatchNorm2d-93           [-1, 48, 35, 35]              96\n",
      "             ReLU-94           [-1, 48, 35, 35]               0\n",
      "        ConvBlock-95           [-1, 48, 35, 35]               0\n",
      "           Conv2d-96           [-1, 64, 35, 35]          27,648\n",
      "      BatchNorm2d-97           [-1, 64, 35, 35]             128\n",
      "             ReLU-98           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-99           [-1, 64, 35, 35]               0\n",
      "          Conv2d-100          [-1, 384, 35, 35]          49,536\n",
      "            ReLU-101          [-1, 384, 35, 35]               0\n",
      "            ReLU-102          [-1, 384, 35, 35]               0\n",
      "   InceptionResA-103          [-1, 384, 35, 35]               0\n",
      "          Conv2d-104           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-105           [-1, 32, 35, 35]              64\n",
      "            ReLU-106           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-107           [-1, 32, 35, 35]               0\n",
      "          Conv2d-108           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-109           [-1, 32, 35, 35]              64\n",
      "            ReLU-110           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-111           [-1, 32, 35, 35]               0\n",
      "          Conv2d-112           [-1, 32, 35, 35]           9,216\n",
      "     BatchNorm2d-113           [-1, 32, 35, 35]              64\n",
      "            ReLU-114           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-115           [-1, 32, 35, 35]               0\n",
      "          Conv2d-116           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-117           [-1, 32, 35, 35]              64\n",
      "            ReLU-118           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-119           [-1, 32, 35, 35]               0\n",
      "          Conv2d-120           [-1, 48, 35, 35]          13,824\n",
      "     BatchNorm2d-121           [-1, 48, 35, 35]              96\n",
      "            ReLU-122           [-1, 48, 35, 35]               0\n",
      "       ConvBlock-123           [-1, 48, 35, 35]               0\n",
      "          Conv2d-124           [-1, 64, 35, 35]          27,648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125           [-1, 64, 35, 35]             128\n",
      "            ReLU-126           [-1, 64, 35, 35]               0\n",
      "       ConvBlock-127           [-1, 64, 35, 35]               0\n",
      "          Conv2d-128          [-1, 384, 35, 35]          49,536\n",
      "            ReLU-129          [-1, 384, 35, 35]               0\n",
      "            ReLU-130          [-1, 384, 35, 35]               0\n",
      "   InceptionResA-131          [-1, 384, 35, 35]               0\n",
      "          Conv2d-132           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-133           [-1, 32, 35, 35]              64\n",
      "            ReLU-134           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-135           [-1, 32, 35, 35]               0\n",
      "          Conv2d-136           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-137           [-1, 32, 35, 35]              64\n",
      "            ReLU-138           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-139           [-1, 32, 35, 35]               0\n",
      "          Conv2d-140           [-1, 32, 35, 35]           9,216\n",
      "     BatchNorm2d-141           [-1, 32, 35, 35]              64\n",
      "            ReLU-142           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-143           [-1, 32, 35, 35]               0\n",
      "          Conv2d-144           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-145           [-1, 32, 35, 35]              64\n",
      "            ReLU-146           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-147           [-1, 32, 35, 35]               0\n",
      "          Conv2d-148           [-1, 48, 35, 35]          13,824\n",
      "     BatchNorm2d-149           [-1, 48, 35, 35]              96\n",
      "            ReLU-150           [-1, 48, 35, 35]               0\n",
      "       ConvBlock-151           [-1, 48, 35, 35]               0\n",
      "          Conv2d-152           [-1, 64, 35, 35]          27,648\n",
      "     BatchNorm2d-153           [-1, 64, 35, 35]             128\n",
      "            ReLU-154           [-1, 64, 35, 35]               0\n",
      "       ConvBlock-155           [-1, 64, 35, 35]               0\n",
      "          Conv2d-156          [-1, 384, 35, 35]          49,536\n",
      "            ReLU-157          [-1, 384, 35, 35]               0\n",
      "            ReLU-158          [-1, 384, 35, 35]               0\n",
      "   InceptionResA-159          [-1, 384, 35, 35]               0\n",
      "          Conv2d-160           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-161           [-1, 32, 35, 35]              64\n",
      "            ReLU-162           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-163           [-1, 32, 35, 35]               0\n",
      "          Conv2d-164           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-165           [-1, 32, 35, 35]              64\n",
      "            ReLU-166           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-167           [-1, 32, 35, 35]               0\n",
      "          Conv2d-168           [-1, 32, 35, 35]           9,216\n",
      "     BatchNorm2d-169           [-1, 32, 35, 35]              64\n",
      "            ReLU-170           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-171           [-1, 32, 35, 35]               0\n",
      "          Conv2d-172           [-1, 32, 35, 35]          12,288\n",
      "     BatchNorm2d-173           [-1, 32, 35, 35]              64\n",
      "            ReLU-174           [-1, 32, 35, 35]               0\n",
      "       ConvBlock-175           [-1, 32, 35, 35]               0\n",
      "          Conv2d-176           [-1, 48, 35, 35]          13,824\n",
      "     BatchNorm2d-177           [-1, 48, 35, 35]              96\n",
      "            ReLU-178           [-1, 48, 35, 35]               0\n",
      "       ConvBlock-179           [-1, 48, 35, 35]               0\n",
      "          Conv2d-180           [-1, 64, 35, 35]          27,648\n",
      "     BatchNorm2d-181           [-1, 64, 35, 35]             128\n",
      "            ReLU-182           [-1, 64, 35, 35]               0\n",
      "       ConvBlock-183           [-1, 64, 35, 35]               0\n",
      "          Conv2d-184          [-1, 384, 35, 35]          49,536\n",
      "            ReLU-185          [-1, 384, 35, 35]               0\n",
      "            ReLU-186          [-1, 384, 35, 35]               0\n",
      "   InceptionResA-187          [-1, 384, 35, 35]               0\n",
      "       MaxPool2d-188          [-1, 384, 17, 17]               0\n",
      "          Conv2d-189          [-1, 384, 17, 17]       1,327,104\n",
      "     BatchNorm2d-190          [-1, 384, 17, 17]             768\n",
      "            ReLU-191          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-192          [-1, 384, 17, 17]               0\n",
      "          Conv2d-193          [-1, 256, 35, 35]          98,304\n",
      "     BatchNorm2d-194          [-1, 256, 35, 35]             512\n",
      "            ReLU-195          [-1, 256, 35, 35]               0\n",
      "       ConvBlock-196          [-1, 256, 35, 35]               0\n",
      "          Conv2d-197          [-1, 256, 35, 35]         589,824\n",
      "     BatchNorm2d-198          [-1, 256, 35, 35]             512\n",
      "            ReLU-199          [-1, 256, 35, 35]               0\n",
      "       ConvBlock-200          [-1, 256, 35, 35]               0\n",
      "          Conv2d-201          [-1, 384, 17, 17]         884,736\n",
      "     BatchNorm2d-202          [-1, 384, 17, 17]             768\n",
      "            ReLU-203          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-204          [-1, 384, 17, 17]               0\n",
      "      ReductionA-205         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-206          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-207          [-1, 192, 17, 17]             384\n",
      "            ReLU-208          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-209          [-1, 192, 17, 17]               0\n",
      "          Conv2d-210          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-211          [-1, 128, 17, 17]             256\n",
      "            ReLU-212          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-213          [-1, 128, 17, 17]               0\n",
      "          Conv2d-214          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-215          [-1, 160, 17, 17]             320\n",
      "            ReLU-216          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-217          [-1, 160, 17, 17]               0\n",
      "          Conv2d-218          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-219          [-1, 192, 17, 17]             384\n",
      "            ReLU-220          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-221          [-1, 192, 17, 17]               0\n",
      "          Conv2d-222         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-223         [-1, 1152, 17, 17]               0\n",
      "            ReLU-224         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-225         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-226          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-227          [-1, 192, 17, 17]             384\n",
      "            ReLU-228          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-229          [-1, 192, 17, 17]               0\n",
      "          Conv2d-230          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-231          [-1, 128, 17, 17]             256\n",
      "            ReLU-232          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-233          [-1, 128, 17, 17]               0\n",
      "          Conv2d-234          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-235          [-1, 160, 17, 17]             320\n",
      "            ReLU-236          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-237          [-1, 160, 17, 17]               0\n",
      "          Conv2d-238          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-239          [-1, 192, 17, 17]             384\n",
      "            ReLU-240          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-241          [-1, 192, 17, 17]               0\n",
      "          Conv2d-242         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-243         [-1, 1152, 17, 17]               0\n",
      "            ReLU-244         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-245         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-246          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-247          [-1, 192, 17, 17]             384\n",
      "            ReLU-248          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-249          [-1, 192, 17, 17]               0\n",
      "          Conv2d-250          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-251          [-1, 128, 17, 17]             256\n",
      "            ReLU-252          [-1, 128, 17, 17]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ConvBlock-253          [-1, 128, 17, 17]               0\n",
      "          Conv2d-254          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-255          [-1, 160, 17, 17]             320\n",
      "            ReLU-256          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-257          [-1, 160, 17, 17]               0\n",
      "          Conv2d-258          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-259          [-1, 192, 17, 17]             384\n",
      "            ReLU-260          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-261          [-1, 192, 17, 17]               0\n",
      "          Conv2d-262         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-263         [-1, 1152, 17, 17]               0\n",
      "            ReLU-264         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-265         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-266          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-267          [-1, 192, 17, 17]             384\n",
      "            ReLU-268          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-269          [-1, 192, 17, 17]               0\n",
      "          Conv2d-270          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-271          [-1, 128, 17, 17]             256\n",
      "            ReLU-272          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-273          [-1, 128, 17, 17]               0\n",
      "          Conv2d-274          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-275          [-1, 160, 17, 17]             320\n",
      "            ReLU-276          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-277          [-1, 160, 17, 17]               0\n",
      "          Conv2d-278          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-279          [-1, 192, 17, 17]             384\n",
      "            ReLU-280          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-281          [-1, 192, 17, 17]               0\n",
      "          Conv2d-282         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-283         [-1, 1152, 17, 17]               0\n",
      "            ReLU-284         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-285         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-286          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-287          [-1, 192, 17, 17]             384\n",
      "            ReLU-288          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-289          [-1, 192, 17, 17]               0\n",
      "          Conv2d-290          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-291          [-1, 128, 17, 17]             256\n",
      "            ReLU-292          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-293          [-1, 128, 17, 17]               0\n",
      "          Conv2d-294          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-295          [-1, 160, 17, 17]             320\n",
      "            ReLU-296          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-297          [-1, 160, 17, 17]               0\n",
      "          Conv2d-298          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-299          [-1, 192, 17, 17]             384\n",
      "            ReLU-300          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-301          [-1, 192, 17, 17]               0\n",
      "          Conv2d-302         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-303         [-1, 1152, 17, 17]               0\n",
      "            ReLU-304         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-305         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-306          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-307          [-1, 192, 17, 17]             384\n",
      "            ReLU-308          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-309          [-1, 192, 17, 17]               0\n",
      "          Conv2d-310          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-311          [-1, 128, 17, 17]             256\n",
      "            ReLU-312          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-313          [-1, 128, 17, 17]               0\n",
      "          Conv2d-314          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-315          [-1, 160, 17, 17]             320\n",
      "            ReLU-316          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-317          [-1, 160, 17, 17]               0\n",
      "          Conv2d-318          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-319          [-1, 192, 17, 17]             384\n",
      "            ReLU-320          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-321          [-1, 192, 17, 17]               0\n",
      "          Conv2d-322         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-323         [-1, 1152, 17, 17]               0\n",
      "            ReLU-324         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-325         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-326          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-327          [-1, 192, 17, 17]             384\n",
      "            ReLU-328          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-329          [-1, 192, 17, 17]               0\n",
      "          Conv2d-330          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-331          [-1, 128, 17, 17]             256\n",
      "            ReLU-332          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-333          [-1, 128, 17, 17]               0\n",
      "          Conv2d-334          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-335          [-1, 160, 17, 17]             320\n",
      "            ReLU-336          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-337          [-1, 160, 17, 17]               0\n",
      "          Conv2d-338          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-339          [-1, 192, 17, 17]             384\n",
      "            ReLU-340          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-341          [-1, 192, 17, 17]               0\n",
      "          Conv2d-342         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-343         [-1, 1152, 17, 17]               0\n",
      "            ReLU-344         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-345         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-346          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-347          [-1, 192, 17, 17]             384\n",
      "            ReLU-348          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-349          [-1, 192, 17, 17]               0\n",
      "          Conv2d-350          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-351          [-1, 128, 17, 17]             256\n",
      "            ReLU-352          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-353          [-1, 128, 17, 17]               0\n",
      "          Conv2d-354          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-355          [-1, 160, 17, 17]             320\n",
      "            ReLU-356          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-357          [-1, 160, 17, 17]               0\n",
      "          Conv2d-358          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-359          [-1, 192, 17, 17]             384\n",
      "            ReLU-360          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-361          [-1, 192, 17, 17]               0\n",
      "          Conv2d-362         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-363         [-1, 1152, 17, 17]               0\n",
      "            ReLU-364         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-365         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-366          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-367          [-1, 192, 17, 17]             384\n",
      "            ReLU-368          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-369          [-1, 192, 17, 17]               0\n",
      "          Conv2d-370          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-371          [-1, 128, 17, 17]             256\n",
      "            ReLU-372          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-373          [-1, 128, 17, 17]               0\n",
      "          Conv2d-374          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-375          [-1, 160, 17, 17]             320\n",
      "            ReLU-376          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-377          [-1, 160, 17, 17]               0\n",
      "          Conv2d-378          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-379          [-1, 192, 17, 17]             384\n",
      "            ReLU-380          [-1, 192, 17, 17]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ConvBlock-381          [-1, 192, 17, 17]               0\n",
      "          Conv2d-382         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-383         [-1, 1152, 17, 17]               0\n",
      "            ReLU-384         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-385         [-1, 1152, 17, 17]               0\n",
      "          Conv2d-386          [-1, 192, 17, 17]         221,184\n",
      "     BatchNorm2d-387          [-1, 192, 17, 17]             384\n",
      "            ReLU-388          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-389          [-1, 192, 17, 17]               0\n",
      "          Conv2d-390          [-1, 128, 17, 17]         147,456\n",
      "     BatchNorm2d-391          [-1, 128, 17, 17]             256\n",
      "            ReLU-392          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-393          [-1, 128, 17, 17]               0\n",
      "          Conv2d-394          [-1, 160, 17, 17]         143,360\n",
      "     BatchNorm2d-395          [-1, 160, 17, 17]             320\n",
      "            ReLU-396          [-1, 160, 17, 17]               0\n",
      "       ConvBlock-397          [-1, 160, 17, 17]               0\n",
      "          Conv2d-398          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-399          [-1, 192, 17, 17]             384\n",
      "            ReLU-400          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-401          [-1, 192, 17, 17]               0\n",
      "          Conv2d-402         [-1, 1152, 17, 17]         443,520\n",
      "            ReLU-403         [-1, 1152, 17, 17]               0\n",
      "            ReLU-404         [-1, 1152, 17, 17]               0\n",
      "   InceptionResB-405         [-1, 1152, 17, 17]               0\n",
      "       MaxPool2d-406           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-407          [-1, 256, 17, 17]         294,912\n",
      "     BatchNorm2d-408          [-1, 256, 17, 17]             512\n",
      "            ReLU-409          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-410          [-1, 256, 17, 17]               0\n",
      "          Conv2d-411            [-1, 384, 8, 8]         884,736\n",
      "     BatchNorm2d-412            [-1, 384, 8, 8]             768\n",
      "            ReLU-413            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-414            [-1, 384, 8, 8]               0\n",
      "          Conv2d-415          [-1, 256, 17, 17]         294,912\n",
      "     BatchNorm2d-416          [-1, 256, 17, 17]             512\n",
      "            ReLU-417          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-418          [-1, 256, 17, 17]               0\n",
      "          Conv2d-419            [-1, 288, 8, 8]         663,552\n",
      "     BatchNorm2d-420            [-1, 288, 8, 8]             576\n",
      "            ReLU-421            [-1, 288, 8, 8]               0\n",
      "       ConvBlock-422            [-1, 288, 8, 8]               0\n",
      "          Conv2d-423          [-1, 256, 17, 17]         294,912\n",
      "     BatchNorm2d-424          [-1, 256, 17, 17]             512\n",
      "            ReLU-425          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-426          [-1, 256, 17, 17]               0\n",
      "          Conv2d-427          [-1, 288, 17, 17]         663,552\n",
      "     BatchNorm2d-428          [-1, 288, 17, 17]             576\n",
      "            ReLU-429          [-1, 288, 17, 17]               0\n",
      "       ConvBlock-430          [-1, 288, 17, 17]               0\n",
      "          Conv2d-431            [-1, 320, 8, 8]         829,440\n",
      "     BatchNorm2d-432            [-1, 320, 8, 8]             640\n",
      "            ReLU-433            [-1, 320, 8, 8]               0\n",
      "       ConvBlock-434            [-1, 320, 8, 8]               0\n",
      "      ReductionB-435           [-1, 2144, 8, 8]               0\n",
      "          Conv2d-436            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-437            [-1, 192, 8, 8]             384\n",
      "            ReLU-438            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-439            [-1, 192, 8, 8]               0\n",
      "          Conv2d-440            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-441            [-1, 192, 8, 8]             384\n",
      "            ReLU-442            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-443            [-1, 192, 8, 8]               0\n",
      "          Conv2d-444            [-1, 224, 8, 8]         129,024\n",
      "     BatchNorm2d-445            [-1, 224, 8, 8]             448\n",
      "            ReLU-446            [-1, 224, 8, 8]               0\n",
      "       ConvBlock-447            [-1, 224, 8, 8]               0\n",
      "          Conv2d-448            [-1, 256, 8, 8]         172,032\n",
      "     BatchNorm2d-449            [-1, 256, 8, 8]             512\n",
      "            ReLU-450            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-451            [-1, 256, 8, 8]               0\n",
      "          Conv2d-452           [-1, 2144, 8, 8]         962,656\n",
      "            ReLU-453           [-1, 2144, 8, 8]               0\n",
      "            ReLU-454           [-1, 2144, 8, 8]               0\n",
      "   InceptionResC-455           [-1, 2144, 8, 8]               0\n",
      "          Conv2d-456            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-457            [-1, 192, 8, 8]             384\n",
      "            ReLU-458            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-459            [-1, 192, 8, 8]               0\n",
      "          Conv2d-460            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-461            [-1, 192, 8, 8]             384\n",
      "            ReLU-462            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-463            [-1, 192, 8, 8]               0\n",
      "          Conv2d-464            [-1, 224, 8, 8]         129,024\n",
      "     BatchNorm2d-465            [-1, 224, 8, 8]             448\n",
      "            ReLU-466            [-1, 224, 8, 8]               0\n",
      "       ConvBlock-467            [-1, 224, 8, 8]               0\n",
      "          Conv2d-468            [-1, 256, 8, 8]         172,032\n",
      "     BatchNorm2d-469            [-1, 256, 8, 8]             512\n",
      "            ReLU-470            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-471            [-1, 256, 8, 8]               0\n",
      "          Conv2d-472           [-1, 2144, 8, 8]         962,656\n",
      "            ReLU-473           [-1, 2144, 8, 8]               0\n",
      "            ReLU-474           [-1, 2144, 8, 8]               0\n",
      "   InceptionResC-475           [-1, 2144, 8, 8]               0\n",
      "          Conv2d-476            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-477            [-1, 192, 8, 8]             384\n",
      "            ReLU-478            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-479            [-1, 192, 8, 8]               0\n",
      "          Conv2d-480            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-481            [-1, 192, 8, 8]             384\n",
      "            ReLU-482            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-483            [-1, 192, 8, 8]               0\n",
      "          Conv2d-484            [-1, 224, 8, 8]         129,024\n",
      "     BatchNorm2d-485            [-1, 224, 8, 8]             448\n",
      "            ReLU-486            [-1, 224, 8, 8]               0\n",
      "       ConvBlock-487            [-1, 224, 8, 8]               0\n",
      "          Conv2d-488            [-1, 256, 8, 8]         172,032\n",
      "     BatchNorm2d-489            [-1, 256, 8, 8]             512\n",
      "            ReLU-490            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-491            [-1, 256, 8, 8]               0\n",
      "          Conv2d-492           [-1, 2144, 8, 8]         962,656\n",
      "            ReLU-493           [-1, 2144, 8, 8]               0\n",
      "            ReLU-494           [-1, 2144, 8, 8]               0\n",
      "   InceptionResC-495           [-1, 2144, 8, 8]               0\n",
      "          Conv2d-496            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-497            [-1, 192, 8, 8]             384\n",
      "            ReLU-498            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-499            [-1, 192, 8, 8]               0\n",
      "          Conv2d-500            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-501            [-1, 192, 8, 8]             384\n",
      "            ReLU-502            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-503            [-1, 192, 8, 8]               0\n",
      "          Conv2d-504            [-1, 224, 8, 8]         129,024\n",
      "     BatchNorm2d-505            [-1, 224, 8, 8]             448\n",
      "            ReLU-506            [-1, 224, 8, 8]               0\n",
      "       ConvBlock-507            [-1, 224, 8, 8]               0\n",
      "          Conv2d-508            [-1, 256, 8, 8]         172,032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-509            [-1, 256, 8, 8]             512\n",
      "            ReLU-510            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-511            [-1, 256, 8, 8]               0\n",
      "          Conv2d-512           [-1, 2144, 8, 8]         962,656\n",
      "            ReLU-513           [-1, 2144, 8, 8]               0\n",
      "            ReLU-514           [-1, 2144, 8, 8]               0\n",
      "   InceptionResC-515           [-1, 2144, 8, 8]               0\n",
      "          Conv2d-516            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-517            [-1, 192, 8, 8]             384\n",
      "            ReLU-518            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-519            [-1, 192, 8, 8]               0\n",
      "          Conv2d-520            [-1, 192, 8, 8]         411,648\n",
      "     BatchNorm2d-521            [-1, 192, 8, 8]             384\n",
      "            ReLU-522            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-523            [-1, 192, 8, 8]               0\n",
      "          Conv2d-524            [-1, 224, 8, 8]         129,024\n",
      "     BatchNorm2d-525            [-1, 224, 8, 8]             448\n",
      "            ReLU-526            [-1, 224, 8, 8]               0\n",
      "       ConvBlock-527            [-1, 224, 8, 8]               0\n",
      "          Conv2d-528            [-1, 256, 8, 8]         172,032\n",
      "     BatchNorm2d-529            [-1, 256, 8, 8]             512\n",
      "            ReLU-530            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-531            [-1, 256, 8, 8]               0\n",
      "          Conv2d-532           [-1, 2144, 8, 8]         962,656\n",
      "            ReLU-533           [-1, 2144, 8, 8]               0\n",
      "            ReLU-534           [-1, 2144, 8, 8]               0\n",
      "   InceptionResC-535           [-1, 2144, 8, 8]               0\n",
      "AdaptiveAvgPool2d-536           [-1, 2144, 1, 1]               0\n",
      "         Dropout-537           [-1, 2144, 1, 1]               0\n",
      "          Linear-538                 [-1, 1000]       2,145,000\n",
      "================================================================\n",
      "Total params: 32,433,928\n",
      "Trainable params: 32,433,928\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 536.02\n",
      "Params size (MB): 123.73\n",
      "Estimated Total Size (MB): 660.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    from torchsummary import summary\n",
    "    model = Inception_ResNet_V2()\n",
    "    summary(model, (3,299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32,433,928 total parameters.\n",
      "32,433,928 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "model = Inception_ResNet_V2()\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
