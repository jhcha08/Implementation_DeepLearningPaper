{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막 AvgPool에서, 논문에 정확한 수치는 없지만 1x1x1536이 되기 위한 숫자를 찾음 \n",
    "\n",
    "\n",
    "- (self.avgpool = nn.AvgPool2d(kernel_size=7, stride=2, padding=0))\n",
    "\n",
    "\n",
    "- 근데 그냥 AdaptiveAvgPool2d로 (1,1) 크기로 바로 만들 수 있음, 지정한 avgpool로 하나 globalavgpool로 하나 모델 파라미터 수는 똑같음\n",
    "\n",
    "\n",
    "- AdaptiveAvgPool2d의 변수 (H,W)로 아웃풋 크기를 지정할 수 있음. 어떤 인풋이 들어와도 저 사이즈대로 맞춰서 만들어줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stem, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvBlock(3, 32, kernel_size=3, stride=2, padding=0),\n",
    "            ConvBlock(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            ConvBlock(32, 64, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.maxpool_96 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.maxpool_192 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.conv_96 = ConvBlock(64, 96, kernel_size=3, stride=2, padding=0)\n",
    "        self.conv_192 = ConvBlock(192, 192, kernel_size=3, stride=2, padding=0) # 논문엔 stride = 2 표시가 안된듯\n",
    "        \n",
    "        self.branch2_1 = nn.Sequential(\n",
    "            ConvBlock(160, 64, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(64, 96, kernel_size=3, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2_2 = nn.Sequential(\n",
    "            ConvBlock(160, 64, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            ConvBlock(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(64, 96, kernel_size=3, stride=1, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.branch1(x)\n",
    "        \n",
    "        x1_1 = self.maxpool_96(x)\n",
    "        x1_2 = self.conv_96(x)\n",
    "        \n",
    "        x = torch.cat([x1_1, x1_2], dim=1)\n",
    "        \n",
    "        x2_1 = self.branch2_1(x)\n",
    "        x2_2 = self.branch2_2(x)\n",
    "        \n",
    "        x = torch.cat([x2_1, x2_2], dim=1)\n",
    "        \n",
    "        x3_1 = self.conv_192(x)\n",
    "        x3_2 = self.maxpool_192(x)\n",
    "        \n",
    "        x = torch.cat([x3_1, x3_2], dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class InceptionA(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(InceptionA, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),          # AvgPool 정보가 논문엔 없는데 이렇게 하니까 됨\n",
    "            ConvBlock(in_ch, 96, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 96, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 64, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(64, 96, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 64, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(96, 96, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x4 = self.branch4(x)\n",
    "        \n",
    "        return torch.cat([x1, x2, x3, x4], dim=1)\n",
    "    \n",
    "    \n",
    "class ReductionA(nn.Module): # k=192, l=224, m=256, n=384\n",
    "    def __init__(self, in_ch, k, l, m, n):\n",
    "        super(ReductionA, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, n, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, k, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(k, l, kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(l, m, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        \n",
    "        return torch.cat([x1, x2, x3], dim=1)\n",
    "    \n",
    "    \n",
    "class InceptionB(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(InceptionB, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_ch, 128, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 384, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 192, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(224, 256, kernel_size=(1,7), stride=1, padding=(0,3)))\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 192, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(192, 192, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(192, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            ConvBlock(224, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(224, 256, kernel_size=(7,1), stride=1, padding=(3,0)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x4 = self.branch4(x)\n",
    "        \n",
    "        return torch.cat([x1, x2, x3, x4], dim=1)\n",
    "    \n",
    "    \n",
    "class ReductionB(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(ReductionB, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 192, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(192, 192, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 256, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            ConvBlock(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            ConvBlock(320, 320, kernel_size=3, stride=2, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        \n",
    "        return torch.cat([x1, x2, x3], dim=1)\n",
    "    \n",
    "    \n",
    "class InceptionC(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(InceptionC, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_ch, 256, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 256, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 384, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        self.conv1x3_br3 = ConvBlock(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        self.conv3x1_br3 = ConvBlock(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            ConvBlock(in_ch, 384, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(384, 448, kernel_size=(1,3), stride=1, padding=(0,1)),\n",
    "            ConvBlock(448, 512, kernel_size=(3,1), stride=1, padding=(1,0)))\n",
    "        \n",
    "        self.conv1x3_br4 = ConvBlock(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        self.conv3x1_br4 = ConvBlock(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        \n",
    "        x3 = self.branch3(x)\n",
    "        \n",
    "        x3_1 = self.conv1x3_br3(x3)\n",
    "        x3_2 = self.conv3x1_br3(x3)\n",
    "        \n",
    "        x3 = torch.cat([x3_1, x3_2], dim=1)\n",
    "        \n",
    "        x4 = self.branch4(x)\n",
    "        \n",
    "        x4_1 = self.conv1x3_br4(x4)\n",
    "        x4_2 = self.conv3x1_br4(x4)\n",
    "        \n",
    "        x4 = torch.cat([x4_1, x4_2], dim=1)\n",
    "        \n",
    "        return torch.cat([x1, x2, x3, x4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV4(nn.Module):\n",
    "    def __init__(self, num_classes = 1000):\n",
    "        super(InceptionV4, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(Stem())\n",
    "        \n",
    "        for _ in range(4):\n",
    "            layers.append(InceptionA(384))\n",
    "            \n",
    "        layers.append(ReductionA(384, 192, 224, 256, 384))\n",
    "        \n",
    "        for _ in range(7):\n",
    "            layers.append(InceptionB(1024))\n",
    "            \n",
    "        layers.append(ReductionB(1024))\n",
    "        \n",
    "        for _ in range(3):\n",
    "            layers.append(InceptionC(1536))\n",
    "        \n",
    "        self.feature = nn.Sequential(*layers)\n",
    "        \n",
    "        self.globalavgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        self.linear = nn.Linear(1536, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.feature(x)     \n",
    "        x = self.globalavgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 149, 149]             864\n",
      "              ReLU-2         [-1, 32, 149, 149]               0\n",
      "         ConvBlock-3         [-1, 32, 149, 149]               0\n",
      "            Conv2d-4         [-1, 32, 147, 147]           9,216\n",
      "              ReLU-5         [-1, 32, 147, 147]               0\n",
      "         ConvBlock-6         [-1, 32, 147, 147]               0\n",
      "            Conv2d-7         [-1, 64, 147, 147]          18,432\n",
      "              ReLU-8         [-1, 64, 147, 147]               0\n",
      "         ConvBlock-9         [-1, 64, 147, 147]               0\n",
      "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
      "           Conv2d-11           [-1, 96, 73, 73]          55,296\n",
      "             ReLU-12           [-1, 96, 73, 73]               0\n",
      "        ConvBlock-13           [-1, 96, 73, 73]               0\n",
      "           Conv2d-14           [-1, 64, 73, 73]          10,240\n",
      "             ReLU-15           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-16           [-1, 64, 73, 73]               0\n",
      "           Conv2d-17           [-1, 96, 71, 71]          55,296\n",
      "             ReLU-18           [-1, 96, 71, 71]               0\n",
      "        ConvBlock-19           [-1, 96, 71, 71]               0\n",
      "           Conv2d-20           [-1, 64, 73, 73]          10,240\n",
      "             ReLU-21           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-22           [-1, 64, 73, 73]               0\n",
      "           Conv2d-23           [-1, 64, 73, 73]          28,672\n",
      "             ReLU-24           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-25           [-1, 64, 73, 73]               0\n",
      "           Conv2d-26           [-1, 64, 73, 73]          28,672\n",
      "             ReLU-27           [-1, 64, 73, 73]               0\n",
      "        ConvBlock-28           [-1, 64, 73, 73]               0\n",
      "           Conv2d-29           [-1, 96, 71, 71]          55,296\n",
      "             ReLU-30           [-1, 96, 71, 71]               0\n",
      "        ConvBlock-31           [-1, 96, 71, 71]               0\n",
      "           Conv2d-32          [-1, 192, 35, 35]         331,776\n",
      "             ReLU-33          [-1, 192, 35, 35]               0\n",
      "        ConvBlock-34          [-1, 192, 35, 35]               0\n",
      "        MaxPool2d-35          [-1, 192, 35, 35]               0\n",
      "             Stem-36          [-1, 384, 35, 35]               0\n",
      "        AvgPool2d-37          [-1, 384, 35, 35]               0\n",
      "           Conv2d-38           [-1, 96, 35, 35]          36,864\n",
      "             ReLU-39           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-40           [-1, 96, 35, 35]               0\n",
      "           Conv2d-41           [-1, 96, 35, 35]          36,864\n",
      "             ReLU-42           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-43           [-1, 96, 35, 35]               0\n",
      "           Conv2d-44           [-1, 64, 35, 35]          24,576\n",
      "             ReLU-45           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-46           [-1, 64, 35, 35]               0\n",
      "           Conv2d-47           [-1, 96, 35, 35]          55,296\n",
      "             ReLU-48           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-49           [-1, 96, 35, 35]               0\n",
      "           Conv2d-50           [-1, 64, 35, 35]          24,576\n",
      "             ReLU-51           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-52           [-1, 64, 35, 35]               0\n",
      "           Conv2d-53           [-1, 96, 35, 35]          55,296\n",
      "             ReLU-54           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-55           [-1, 96, 35, 35]               0\n",
      "           Conv2d-56           [-1, 96, 35, 35]          82,944\n",
      "             ReLU-57           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-58           [-1, 96, 35, 35]               0\n",
      "       InceptionA-59          [-1, 384, 35, 35]               0\n",
      "        AvgPool2d-60          [-1, 384, 35, 35]               0\n",
      "           Conv2d-61           [-1, 96, 35, 35]          36,864\n",
      "             ReLU-62           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-63           [-1, 96, 35, 35]               0\n",
      "           Conv2d-64           [-1, 96, 35, 35]          36,864\n",
      "             ReLU-65           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-66           [-1, 96, 35, 35]               0\n",
      "           Conv2d-67           [-1, 64, 35, 35]          24,576\n",
      "             ReLU-68           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-69           [-1, 64, 35, 35]               0\n",
      "           Conv2d-70           [-1, 96, 35, 35]          55,296\n",
      "             ReLU-71           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-72           [-1, 96, 35, 35]               0\n",
      "           Conv2d-73           [-1, 64, 35, 35]          24,576\n",
      "             ReLU-74           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-75           [-1, 64, 35, 35]               0\n",
      "           Conv2d-76           [-1, 96, 35, 35]          55,296\n",
      "             ReLU-77           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-78           [-1, 96, 35, 35]               0\n",
      "           Conv2d-79           [-1, 96, 35, 35]          82,944\n",
      "             ReLU-80           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-81           [-1, 96, 35, 35]               0\n",
      "       InceptionA-82          [-1, 384, 35, 35]               0\n",
      "        AvgPool2d-83          [-1, 384, 35, 35]               0\n",
      "           Conv2d-84           [-1, 96, 35, 35]          36,864\n",
      "             ReLU-85           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-86           [-1, 96, 35, 35]               0\n",
      "           Conv2d-87           [-1, 96, 35, 35]          36,864\n",
      "             ReLU-88           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-89           [-1, 96, 35, 35]               0\n",
      "           Conv2d-90           [-1, 64, 35, 35]          24,576\n",
      "             ReLU-91           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-92           [-1, 64, 35, 35]               0\n",
      "           Conv2d-93           [-1, 96, 35, 35]          55,296\n",
      "             ReLU-94           [-1, 96, 35, 35]               0\n",
      "        ConvBlock-95           [-1, 96, 35, 35]               0\n",
      "           Conv2d-96           [-1, 64, 35, 35]          24,576\n",
      "             ReLU-97           [-1, 64, 35, 35]               0\n",
      "        ConvBlock-98           [-1, 64, 35, 35]               0\n",
      "           Conv2d-99           [-1, 96, 35, 35]          55,296\n",
      "            ReLU-100           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-101           [-1, 96, 35, 35]               0\n",
      "          Conv2d-102           [-1, 96, 35, 35]          82,944\n",
      "            ReLU-103           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-104           [-1, 96, 35, 35]               0\n",
      "      InceptionA-105          [-1, 384, 35, 35]               0\n",
      "       AvgPool2d-106          [-1, 384, 35, 35]               0\n",
      "          Conv2d-107           [-1, 96, 35, 35]          36,864\n",
      "            ReLU-108           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-109           [-1, 96, 35, 35]               0\n",
      "          Conv2d-110           [-1, 96, 35, 35]          36,864\n",
      "            ReLU-111           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-112           [-1, 96, 35, 35]               0\n",
      "          Conv2d-113           [-1, 64, 35, 35]          24,576\n",
      "            ReLU-114           [-1, 64, 35, 35]               0\n",
      "       ConvBlock-115           [-1, 64, 35, 35]               0\n",
      "          Conv2d-116           [-1, 96, 35, 35]          55,296\n",
      "            ReLU-117           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-118           [-1, 96, 35, 35]               0\n",
      "          Conv2d-119           [-1, 64, 35, 35]          24,576\n",
      "            ReLU-120           [-1, 64, 35, 35]               0\n",
      "       ConvBlock-121           [-1, 64, 35, 35]               0\n",
      "          Conv2d-122           [-1, 96, 35, 35]          55,296\n",
      "            ReLU-123           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-124           [-1, 96, 35, 35]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-125           [-1, 96, 35, 35]          82,944\n",
      "            ReLU-126           [-1, 96, 35, 35]               0\n",
      "       ConvBlock-127           [-1, 96, 35, 35]               0\n",
      "      InceptionA-128          [-1, 384, 35, 35]               0\n",
      "       MaxPool2d-129          [-1, 384, 17, 17]               0\n",
      "          Conv2d-130          [-1, 384, 17, 17]       1,327,104\n",
      "            ReLU-131          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-132          [-1, 384, 17, 17]               0\n",
      "          Conv2d-133          [-1, 192, 35, 35]          73,728\n",
      "            ReLU-134          [-1, 192, 35, 35]               0\n",
      "       ConvBlock-135          [-1, 192, 35, 35]               0\n",
      "          Conv2d-136          [-1, 224, 35, 35]         387,072\n",
      "            ReLU-137          [-1, 224, 35, 35]               0\n",
      "       ConvBlock-138          [-1, 224, 35, 35]               0\n",
      "          Conv2d-139          [-1, 256, 17, 17]         516,096\n",
      "            ReLU-140          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-141          [-1, 256, 17, 17]               0\n",
      "      ReductionA-142         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-143         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-144          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-145          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-146          [-1, 128, 17, 17]               0\n",
      "          Conv2d-147          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-148          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-149          [-1, 384, 17, 17]               0\n",
      "          Conv2d-150          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-151          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-152          [-1, 192, 17, 17]               0\n",
      "          Conv2d-153          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-154          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-155          [-1, 224, 17, 17]               0\n",
      "          Conv2d-156          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-157          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-158          [-1, 256, 17, 17]               0\n",
      "          Conv2d-159          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-160          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-161          [-1, 192, 17, 17]               0\n",
      "          Conv2d-162          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-163          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-164          [-1, 192, 17, 17]               0\n",
      "          Conv2d-165          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-166          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-167          [-1, 224, 17, 17]               0\n",
      "          Conv2d-168          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-169          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-170          [-1, 224, 17, 17]               0\n",
      "          Conv2d-171          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-172          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-173          [-1, 256, 17, 17]               0\n",
      "      InceptionB-174         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-175         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-176          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-177          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-178          [-1, 128, 17, 17]               0\n",
      "          Conv2d-179          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-180          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-181          [-1, 384, 17, 17]               0\n",
      "          Conv2d-182          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-183          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-184          [-1, 192, 17, 17]               0\n",
      "          Conv2d-185          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-186          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-187          [-1, 224, 17, 17]               0\n",
      "          Conv2d-188          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-189          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-190          [-1, 256, 17, 17]               0\n",
      "          Conv2d-191          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-192          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-193          [-1, 192, 17, 17]               0\n",
      "          Conv2d-194          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-195          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-196          [-1, 192, 17, 17]               0\n",
      "          Conv2d-197          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-198          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-199          [-1, 224, 17, 17]               0\n",
      "          Conv2d-200          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-201          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-202          [-1, 224, 17, 17]               0\n",
      "          Conv2d-203          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-204          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-205          [-1, 256, 17, 17]               0\n",
      "      InceptionB-206         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-207         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-208          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-209          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-210          [-1, 128, 17, 17]               0\n",
      "          Conv2d-211          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-212          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-213          [-1, 384, 17, 17]               0\n",
      "          Conv2d-214          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-215          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-216          [-1, 192, 17, 17]               0\n",
      "          Conv2d-217          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-218          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-219          [-1, 224, 17, 17]               0\n",
      "          Conv2d-220          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-221          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-222          [-1, 256, 17, 17]               0\n",
      "          Conv2d-223          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-224          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-225          [-1, 192, 17, 17]               0\n",
      "          Conv2d-226          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-227          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-228          [-1, 192, 17, 17]               0\n",
      "          Conv2d-229          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-230          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-231          [-1, 224, 17, 17]               0\n",
      "          Conv2d-232          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-233          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-234          [-1, 224, 17, 17]               0\n",
      "          Conv2d-235          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-236          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-237          [-1, 256, 17, 17]               0\n",
      "      InceptionB-238         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-239         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-240          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-241          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-242          [-1, 128, 17, 17]               0\n",
      "          Conv2d-243          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-244          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-245          [-1, 384, 17, 17]               0\n",
      "          Conv2d-246          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-247          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-248          [-1, 192, 17, 17]               0\n",
      "          Conv2d-249          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-250          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-251          [-1, 224, 17, 17]               0\n",
      "          Conv2d-252          [-1, 256, 17, 17]         401,408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ReLU-253          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-254          [-1, 256, 17, 17]               0\n",
      "          Conv2d-255          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-256          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-257          [-1, 192, 17, 17]               0\n",
      "          Conv2d-258          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-259          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-260          [-1, 192, 17, 17]               0\n",
      "          Conv2d-261          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-262          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-263          [-1, 224, 17, 17]               0\n",
      "          Conv2d-264          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-265          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-266          [-1, 224, 17, 17]               0\n",
      "          Conv2d-267          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-268          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-269          [-1, 256, 17, 17]               0\n",
      "      InceptionB-270         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-271         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-272          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-273          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-274          [-1, 128, 17, 17]               0\n",
      "          Conv2d-275          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-276          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-277          [-1, 384, 17, 17]               0\n",
      "          Conv2d-278          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-279          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-280          [-1, 192, 17, 17]               0\n",
      "          Conv2d-281          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-282          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-283          [-1, 224, 17, 17]               0\n",
      "          Conv2d-284          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-285          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-286          [-1, 256, 17, 17]               0\n",
      "          Conv2d-287          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-288          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-289          [-1, 192, 17, 17]               0\n",
      "          Conv2d-290          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-291          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-292          [-1, 192, 17, 17]               0\n",
      "          Conv2d-293          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-294          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-295          [-1, 224, 17, 17]               0\n",
      "          Conv2d-296          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-297          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-298          [-1, 224, 17, 17]               0\n",
      "          Conv2d-299          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-300          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-301          [-1, 256, 17, 17]               0\n",
      "      InceptionB-302         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-303         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-304          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-305          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-306          [-1, 128, 17, 17]               0\n",
      "          Conv2d-307          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-308          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-309          [-1, 384, 17, 17]               0\n",
      "          Conv2d-310          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-311          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-312          [-1, 192, 17, 17]               0\n",
      "          Conv2d-313          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-314          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-315          [-1, 224, 17, 17]               0\n",
      "          Conv2d-316          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-317          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-318          [-1, 256, 17, 17]               0\n",
      "          Conv2d-319          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-320          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-321          [-1, 192, 17, 17]               0\n",
      "          Conv2d-322          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-323          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-324          [-1, 192, 17, 17]               0\n",
      "          Conv2d-325          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-326          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-327          [-1, 224, 17, 17]               0\n",
      "          Conv2d-328          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-329          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-330          [-1, 224, 17, 17]               0\n",
      "          Conv2d-331          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-332          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-333          [-1, 256, 17, 17]               0\n",
      "      InceptionB-334         [-1, 1024, 17, 17]               0\n",
      "       AvgPool2d-335         [-1, 1024, 17, 17]               0\n",
      "          Conv2d-336          [-1, 128, 17, 17]         131,072\n",
      "            ReLU-337          [-1, 128, 17, 17]               0\n",
      "       ConvBlock-338          [-1, 128, 17, 17]               0\n",
      "          Conv2d-339          [-1, 384, 17, 17]         393,216\n",
      "            ReLU-340          [-1, 384, 17, 17]               0\n",
      "       ConvBlock-341          [-1, 384, 17, 17]               0\n",
      "          Conv2d-342          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-343          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-344          [-1, 192, 17, 17]               0\n",
      "          Conv2d-345          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-346          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-347          [-1, 224, 17, 17]               0\n",
      "          Conv2d-348          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-349          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-350          [-1, 256, 17, 17]               0\n",
      "          Conv2d-351          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-352          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-353          [-1, 192, 17, 17]               0\n",
      "          Conv2d-354          [-1, 192, 17, 17]         258,048\n",
      "            ReLU-355          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-356          [-1, 192, 17, 17]               0\n",
      "          Conv2d-357          [-1, 224, 17, 17]         301,056\n",
      "            ReLU-358          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-359          [-1, 224, 17, 17]               0\n",
      "          Conv2d-360          [-1, 224, 17, 17]         351,232\n",
      "            ReLU-361          [-1, 224, 17, 17]               0\n",
      "       ConvBlock-362          [-1, 224, 17, 17]               0\n",
      "          Conv2d-363          [-1, 256, 17, 17]         401,408\n",
      "            ReLU-364          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-365          [-1, 256, 17, 17]               0\n",
      "      InceptionB-366         [-1, 1024, 17, 17]               0\n",
      "       MaxPool2d-367           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-368          [-1, 192, 17, 17]         196,608\n",
      "            ReLU-369          [-1, 192, 17, 17]               0\n",
      "       ConvBlock-370          [-1, 192, 17, 17]               0\n",
      "          Conv2d-371            [-1, 192, 8, 8]         331,776\n",
      "            ReLU-372            [-1, 192, 8, 8]               0\n",
      "       ConvBlock-373            [-1, 192, 8, 8]               0\n",
      "          Conv2d-374          [-1, 256, 17, 17]         262,144\n",
      "            ReLU-375          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-376          [-1, 256, 17, 17]               0\n",
      "          Conv2d-377          [-1, 256, 17, 17]         458,752\n",
      "            ReLU-378          [-1, 256, 17, 17]               0\n",
      "       ConvBlock-379          [-1, 256, 17, 17]               0\n",
      "          Conv2d-380          [-1, 320, 17, 17]         573,440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ReLU-381          [-1, 320, 17, 17]               0\n",
      "       ConvBlock-382          [-1, 320, 17, 17]               0\n",
      "          Conv2d-383            [-1, 320, 8, 8]         921,600\n",
      "            ReLU-384            [-1, 320, 8, 8]               0\n",
      "       ConvBlock-385            [-1, 320, 8, 8]               0\n",
      "      ReductionB-386           [-1, 1536, 8, 8]               0\n",
      "       AvgPool2d-387           [-1, 1536, 8, 8]               0\n",
      "          Conv2d-388            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-389            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-390            [-1, 256, 8, 8]               0\n",
      "          Conv2d-391            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-392            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-393            [-1, 256, 8, 8]               0\n",
      "          Conv2d-394            [-1, 384, 8, 8]         589,824\n",
      "            ReLU-395            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-396            [-1, 384, 8, 8]               0\n",
      "          Conv2d-397            [-1, 256, 8, 8]         294,912\n",
      "            ReLU-398            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-399            [-1, 256, 8, 8]               0\n",
      "          Conv2d-400            [-1, 256, 8, 8]         294,912\n",
      "            ReLU-401            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-402            [-1, 256, 8, 8]               0\n",
      "          Conv2d-403            [-1, 384, 8, 8]         589,824\n",
      "            ReLU-404            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-405            [-1, 384, 8, 8]               0\n",
      "          Conv2d-406            [-1, 448, 8, 8]         516,096\n",
      "            ReLU-407            [-1, 448, 8, 8]               0\n",
      "       ConvBlock-408            [-1, 448, 8, 8]               0\n",
      "          Conv2d-409            [-1, 512, 8, 8]         688,128\n",
      "            ReLU-410            [-1, 512, 8, 8]               0\n",
      "       ConvBlock-411            [-1, 512, 8, 8]               0\n",
      "          Conv2d-412            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-413            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-414            [-1, 256, 8, 8]               0\n",
      "          Conv2d-415            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-416            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-417            [-1, 256, 8, 8]               0\n",
      "      InceptionC-418           [-1, 1536, 8, 8]               0\n",
      "       AvgPool2d-419           [-1, 1536, 8, 8]               0\n",
      "          Conv2d-420            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-421            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-422            [-1, 256, 8, 8]               0\n",
      "          Conv2d-423            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-424            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-425            [-1, 256, 8, 8]               0\n",
      "          Conv2d-426            [-1, 384, 8, 8]         589,824\n",
      "            ReLU-427            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-428            [-1, 384, 8, 8]               0\n",
      "          Conv2d-429            [-1, 256, 8, 8]         294,912\n",
      "            ReLU-430            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-431            [-1, 256, 8, 8]               0\n",
      "          Conv2d-432            [-1, 256, 8, 8]         294,912\n",
      "            ReLU-433            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-434            [-1, 256, 8, 8]               0\n",
      "          Conv2d-435            [-1, 384, 8, 8]         589,824\n",
      "            ReLU-436            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-437            [-1, 384, 8, 8]               0\n",
      "          Conv2d-438            [-1, 448, 8, 8]         516,096\n",
      "            ReLU-439            [-1, 448, 8, 8]               0\n",
      "       ConvBlock-440            [-1, 448, 8, 8]               0\n",
      "          Conv2d-441            [-1, 512, 8, 8]         688,128\n",
      "            ReLU-442            [-1, 512, 8, 8]               0\n",
      "       ConvBlock-443            [-1, 512, 8, 8]               0\n",
      "          Conv2d-444            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-445            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-446            [-1, 256, 8, 8]               0\n",
      "          Conv2d-447            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-448            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-449            [-1, 256, 8, 8]               0\n",
      "      InceptionC-450           [-1, 1536, 8, 8]               0\n",
      "       AvgPool2d-451           [-1, 1536, 8, 8]               0\n",
      "          Conv2d-452            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-453            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-454            [-1, 256, 8, 8]               0\n",
      "          Conv2d-455            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-456            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-457            [-1, 256, 8, 8]               0\n",
      "          Conv2d-458            [-1, 384, 8, 8]         589,824\n",
      "            ReLU-459            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-460            [-1, 384, 8, 8]               0\n",
      "          Conv2d-461            [-1, 256, 8, 8]         294,912\n",
      "            ReLU-462            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-463            [-1, 256, 8, 8]               0\n",
      "          Conv2d-464            [-1, 256, 8, 8]         294,912\n",
      "            ReLU-465            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-466            [-1, 256, 8, 8]               0\n",
      "          Conv2d-467            [-1, 384, 8, 8]         589,824\n",
      "            ReLU-468            [-1, 384, 8, 8]               0\n",
      "       ConvBlock-469            [-1, 384, 8, 8]               0\n",
      "          Conv2d-470            [-1, 448, 8, 8]         516,096\n",
      "            ReLU-471            [-1, 448, 8, 8]               0\n",
      "       ConvBlock-472            [-1, 448, 8, 8]               0\n",
      "          Conv2d-473            [-1, 512, 8, 8]         688,128\n",
      "            ReLU-474            [-1, 512, 8, 8]               0\n",
      "       ConvBlock-475            [-1, 512, 8, 8]               0\n",
      "          Conv2d-476            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-477            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-478            [-1, 256, 8, 8]               0\n",
      "          Conv2d-479            [-1, 256, 8, 8]         393,216\n",
      "            ReLU-480            [-1, 256, 8, 8]               0\n",
      "       ConvBlock-481            [-1, 256, 8, 8]               0\n",
      "      InceptionC-482           [-1, 1536, 8, 8]               0\n",
      "AdaptiveAvgPool2d-483           [-1, 1536, 1, 1]               0\n",
      "         Dropout-484           [-1, 1536, 1, 1]               0\n",
      "          Linear-485                 [-1, 1000]       1,537,000\n",
      "================================================================\n",
      "Total params: 42,616,648\n",
      "Trainable params: 42,616,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 422.56\n",
      "Params size (MB): 162.57\n",
      "Estimated Total Size (MB): 586.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    from torchsummary import summary\n",
    "    model = InceptionV4()\n",
    "    summary(model, (3,299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42,616,648 total parameters.\n",
      "42,616,648 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "model = InceptionV4()\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
