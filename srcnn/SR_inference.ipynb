{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SR Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWqTXjKMV995"
   },
   "outputs": [],
   "source": [
    "# ESA_SAPEON_bigger_B3_x2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def conv_layer(in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1):\n",
    "    padding = int((kernel_size - 1) / 2) * dilation\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, bias=True, dilation=dilation,\n",
    "                     groups=groups)\n",
    "\n",
    "\n",
    "def norm(norm_type, nc):\n",
    "    norm_type = norm_type.lower()\n",
    "    if norm_type == 'batch':\n",
    "        layer = nn.BatchNorm2d(nc, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [{:s}] is not found'.format(norm_type))\n",
    "    return layer\n",
    "\n",
    "\n",
    "def pad(pad_type, padding):\n",
    "    pad_type = pad_type.lower()\n",
    "    if padding == 0:\n",
    "        return None\n",
    "    if pad_type == 'reflect':\n",
    "        layer = nn.ReflectionPad2d(padding)\n",
    "    elif pad_type == 'replicate':\n",
    "        layer = nn.ReplicationPad2d(padding)\n",
    "    else:\n",
    "        raise NotImplementedError('padding layer [{:s}] is not implemented'.format(pad_type))\n",
    "    return layer\n",
    "\n",
    "\n",
    "def get_valid_padding(kernel_size, dilation):\n",
    "    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    padding = (kernel_size - 1) // 2\n",
    "    return padding\n",
    "\n",
    "\n",
    "def conv_block(in_nc, out_nc, kernel_size, stride=1, dilation=1, groups=1, bias=True,\n",
    "               pad_type='zero', norm_type=None, act_type='relu'):\n",
    "    padding = get_valid_padding(kernel_size, dilation)\n",
    "    p = pad(pad_type, padding) if pad_type and pad_type != 'zero' else None\n",
    "    padding = padding if pad_type == 'zero' else 0\n",
    "\n",
    "    c = nn.Conv2d(in_nc, out_nc, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                  dilation=dilation, bias=bias, groups=groups)\n",
    "    a = activation(act_type) if act_type else None\n",
    "    n = norm(norm_type, out_nc) if norm_type else None\n",
    "    return sequential(p, c, n, a)\n",
    "\n",
    "\n",
    "def activation(act_type, inplace=True, neg_slope=0.05, n_prelu=1):\n",
    "    act_type = act_type.lower()\n",
    "    if act_type == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act_type == 'lrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act_type == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    else:\n",
    "        raise NotImplementedError('activation layer [{:s}] is not found'.format(act_type))\n",
    "    return layer\n",
    "    \n",
    "def pixelshuffle_block(in_channels, out_channels, upscale_factor=3, kernel_size=3, stride=1):\n",
    "    if upscale_factor == 3:\n",
    "        conv = conv_layer(in_channels, 9 * out_channels, 3, stride)\n",
    "        pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    else :\n",
    "        conv = conv_layer(in_channels, out_channels * (upscale_factor ** 2), kernel_size, stride)\n",
    "        pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    return sequential(conv, pixel_shuffle)\n",
    "\n",
    "def mean_channels(F):\n",
    "    assert(F.dim() == 4)\n",
    "    spatial_sum = F.sum(3, keepdim=True).sum(2, keepdim=True)\n",
    "    return spatial_sum / (F.size(2) * F.size(3))\n",
    "\n",
    "def stdv_channels(F):\n",
    "    assert(F.dim() == 4)\n",
    "    F_mean = mean_channels(F)\n",
    "    F_variance = (F - F_mean).pow(2).sum(3, keepdim=True).sum(2, keepdim=True) / (F.size(2) * F.size(3))\n",
    "    return F_variance.pow(0.5)\n",
    "\n",
    "def sequential(*args):\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], OrderedDict):\n",
    "            raise NotImplementedError('sequential does not support OrderedDict input.')\n",
    "        return args[0]\n",
    "    modules = []\n",
    "    for module in args:\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for submodule in module.children():\n",
    "                modules.append(submodule)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            modules.append(module)\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "\n",
    "class ESA(nn.Module):\n",
    "    def __init__(self, n_feats, conv):\n",
    "        super(ESA, self).__init__()\n",
    "        f = n_feats // 4\n",
    "        self.conv1 = conv(n_feats, f, kernel_size=1)\n",
    "        self.conv_f = conv(f, f, kernel_size=1)\n",
    "        self.conv_max = conv(f, f, kernel_size=3, padding=1)\n",
    "        self.conv2 = conv(f, f, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = conv(f, f, kernel_size=3, padding=1)\n",
    "        self.conv3_ = conv(f, f, kernel_size=3, padding=1)\n",
    "        #upsample_block = pixelshuffle_block\n",
    "        #self.upsampler = upsample_block(f, f, upscale_factor=8)\n",
    "        self.conv4 = conv(f, n_feats, kernel_size=1)        \n",
    "        self.clip_with = nn.ReLU6()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1_ = (self.conv1(x))\n",
    "        c1 = self.conv2(c1_) #F.avg_pool2d(c1_, kernel_size=2, stride=2)\n",
    "        v_max = F.max_pool2d(c1, kernel_size=4, stride=4)\n",
    "        v_range = self.relu(self.conv_max(v_max))\n",
    "        c3 = self.relu(self.conv3(v_range))\n",
    "        c3 = self.conv3_(c3)\n",
    "        #c3 = self.upsampler(c3) # x2에서는 pixelshuffle이 문제되는 것으로 보여 임시로 interpolate로 upsample함\n",
    "        c3 = F.interpolate(c3, (x.size(2), x.size(3)), mode='bicubic', align_corners=False)\n",
    "        cf = self.conv_f(c1_)\n",
    "        c4 = self.conv4(c3+cf)\n",
    "        m = self.clip_with(c4)\n",
    "        return x * m\n",
    "\n",
    "\n",
    "class RFDB(nn.Module):\n",
    "    def __init__(self, in_channels, distillation_rate=0.25):\n",
    "        super(RFDB, self).__init__()\n",
    "        self.dc = self.distilled_channels = in_channels//2\n",
    "        self.rc = self.remaining_channels = in_channels\n",
    "        self.c1_d = conv_layer(in_channels, self.dc, 1)\n",
    "        self.c1_r = conv_layer(in_channels, self.rc, 3)\n",
    "        self.c2_d = conv_layer(self.remaining_channels, self.dc, 1)\n",
    "        self.c2_r = conv_layer(self.remaining_channels, self.rc, 3)\n",
    "        self.c4 = conv_layer(self.remaining_channels, self.dc, 3)\n",
    "        self.act = activation('relu', neg_slope=0.05) # lrelu\n",
    "        self.c5 = conv_layer(self.dc*4, in_channels, 1)\n",
    "        self.esa = ESA(in_channels, nn.Conv2d)\n",
    "\n",
    "    def forward(self, input):\n",
    "        distilled_c1 = self.act(self.c1_d(input))\n",
    "        r_c1 = self.act(self.c1_r(input))\n",
    "        r_c1 = r_c1+input\n",
    "\n",
    "        distilled_c2 = self.act(self.c2_d(r_c1))\n",
    "        r_c2 = self.act(self.c2_r(r_c1))\n",
    "        r_c2 = r_c2+r_c1\n",
    "\n",
    "        r_c4 = self.act(self.c4(r_c2))\n",
    "\n",
    "        out = torch.cat([distilled_c1, distilled_c2, r_c4, r_c4], dim=1)\n",
    "        out_fused = self.esa(self.act(self.c5(out)))\n",
    "\n",
    "        return out_fused\n",
    "\n",
    "\n",
    "class RFDN64(nn.Module):\n",
    "    def __init__(self, in_nc=3, nf=64, num_modules=3, out_nc=3, upscale=3):\n",
    "        super(RFDN64, self).__init__()\n",
    "\n",
    "        self.fea_conv = conv_layer(in_nc, nf, kernel_size=3)\n",
    "\n",
    "        self.B1 = RFDB(in_channels=nf)\n",
    "        self.B2 = RFDB(in_channels=nf)\n",
    "        self.B3 = RFDB(in_channels=nf)\n",
    "\n",
    "        self.c = conv_block(nf * num_modules, nf, kernel_size=3, act_type='relu') # lrelu\n",
    "\n",
    "        upsample_block = pixelshuffle_block\n",
    "        self.upsampler = upsample_block(nf, out_nc, upscale_factor=upscale)\n",
    "        self.scale_idx = 0\n",
    "        self.init = 0\n",
    "\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, input):        \n",
    "\n",
    "        out_fea = self.act(self.fea_conv(input))\n",
    "        out_B1 = self.B1(out_fea)\n",
    "        out_B2 = self.B2(out_B1)\n",
    "        out_B3 = self.B3(out_B2)\n",
    "\n",
    "        out_B = self.c(torch.cat([out_B1, out_B2, out_B3], dim=1))\n",
    "\n",
    "        out_lr = out_B + out_fea + out_B3\n",
    "\n",
    "        output = self.upsampler(out_lr)\n",
    "        output = torch.clamp(output, min=0, max=1)    \n",
    "\n",
    "        return output\n",
    "\n",
    "    def set_scale(self, scale_idx):\n",
    "        self.scale_idx = scale_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV_BGDs4qZL_"
   },
   "source": [
    "## 모델이 RGB input, PixelShuffle upsample일때만 동작 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2706,
     "status": "ok",
     "timestamp": 1630503408837,
     "user": {
      "displayName": "차정훈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6xfHEoVdjEJ4nV7mmInM9vvYue0PAZ2x7u-co=s64",
      "userId": "17408755466079675051"
     },
     "user_tz": -540
    },
    "id": "mt6o9uraptbo",
    "outputId": "76cd5af5-7385-4cab-d420-507a07f948d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image size 960x540\n",
      "torch.Size([1, 3, 540, 960])\n",
      "torch.Size([1, 3, 1080, 1920])\n",
      "output image saved to  kaimedia_sample_result_3220.png\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "img = Image.open('kaimedia_sample_3220.png').convert('RGB')\n",
    "img = img.resize((960,540),Image.BICUBIC) # 이미지 크기가 작다면 resize 과정 필요 X\n",
    "img.save('kaimedia_sample_after_bic_3220.png')\n",
    "\n",
    "print('input image size {:d}x{:d}'.format(img.size[0], img.size[1]))\n",
    "\n",
    "model = RFDN64(upscale=2)\n",
    "\n",
    "state_dict = torch.load('kaimedia_star_model.pth') # 추론에 쓸 모델 가중치 필요\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "img_to_tensor = ToTensor()\n",
    "input = img_to_tensor(img).view(1, -1, img.size[1], img.size[0])\n",
    "\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model) # train을 이걸로 했으면 지금처럼 추론때도 해줘야 함.\n",
    "input = input.cuda()\n",
    "\n",
    "print(input.size())\n",
    "\n",
    "out = model(input)\n",
    "out = out.cpu()\n",
    "\n",
    "print(out.size())\n",
    "\n",
    "out_img = out[0].detach().numpy()\n",
    "out_img *= 255.0\n",
    "out_img = out_img.clip(0, 255)\n",
    "out_img = np.transpose(out_img,(1,2,0))\n",
    "out_img = np.uint8(out_img)\n",
    "\n",
    "out_img = Image.fromarray(out_img, mode='RGB')\n",
    "out_img.save('kaimedia_sample_result_3220.png')\n",
    "\n",
    "print('output image saved to ', 'kaimedia_sample_result_3220.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPaugOcUumq9TxL76AbQTBS",
   "collapsed_sections": [],
   "name": "kaimediaStar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
